---
title: "Short Course Examples"
format: 
  html:
    warning: false
    message: false
editor: visual
---

# Example 1: Logistic Regression

```{r}
library(tidyverse)
library(tidymodels)
```

We're going to use a simple dataset linking individual health and demographic information to stroke risk:

```{r}
## Read in the data

stroke <- read_csv("./stroke.csv") %>% 
  select(stroke, gender, age, hypertension)

head(stroke)
```

We start by fiitting a standard logistic regression model:

```{r}
# Fit a logistic regression model
pred_model <- glm(stroke ~ gender + age + hypertension,
                  data = stroke,
                  family = "binomial")

summary(pred_model)
```

That's it, we've got our prediction model! Now to get predicted (i.e., fitted) values for our original sample, we can use the `predict` function:

```{r}
hist(predict(pred_model, type = "response"))


```

To make a prediction for a "new" individual, we do:

```{r}
# Make a prediction for a "new" individual:
new_data <- data.frame(gender = "Female",
                       age = 78,
                       hypertension = 1)

new_pred <- predict(pred_model, 
                    newdata = new_data, 
                    type = "response")

new_pred
```

# Example 2: Overfitting

```{r}
library(ranger)
library(gbm)
library(rpart)
library(pROC)

```

We'll start by reading in the stroke dataset again, using a few more variables this time.

```{r}
stroke <- read_csv("./stroke.csv") %>%
  mutate(stroke = factor(stroke),
         across(c(gender, ever_married, work_type, Residence_type, smoking_status), as.factor)) %>%
  filter(gender != "Other") ## To avoid fitting issues

```

Next, we'll split it into two random subsets (we'll see why in a minute):

```{r}
## Random half of the data
stroke_1 <- stroke %>% sample_frac(0.5)

## Other half of the data
stroke_2 <- stroke %>% 
  filter(!(id %in% stroke_1$id))
```

Now, let's fit two prediction models (a logistic regression and a random forest) on the first random partition of the data, get the corresponding predictions, and calculate the AUCs:

```{r}
##### Fit the models on stroke_1 and get predictions (on stroke_1)

## Logistic regression model
M1 <- glm(stroke ~ . -id, data = stroke_1, family = "binomial")
pred_M1 <- predict(M1, type = "response")

## Random forest
M2 <- ranger(stroke ~ . -id, probability = TRUE,
             data = stroke_1)
pred_M2 <- predict(M2, data = stroke_1, type = "response")$predictions[, 2]

## Add the predictions to the dataset
stroke_1_pred <- stroke_1 %>%
  mutate(pred_M1 = pred_M1,
         pred_M2 = pred_M2)

## Calculate the AUCs
roc(stroke ~ pred_M1, data = stroke_1_pred)$auc
roc(stroke ~ pred_M2, data = stroke_1_pred)$auc

```

OK, now we apply the models fitted to the first partition to make predictions on data from the second partition:

```{r}
##### Use the models fitted on stroke_1 to get predictions on stroke_2

pred_M1_new <- predict(M1, 
                       newdata = stroke_2,
                       type = "response")

pred_M2_new <- predict(M2, 
                   data = stroke_2,
                   type = "response")$predictions[, 2]

## Add the predictions to the dataset
stroke_2_pred <- stroke_2 %>%
  mutate(pred_M1_new = pred_M1_new,
         pred_M2_new = pred_M2_new)

## Re-calculate the AUCs
roc(stroke ~ pred_M1_new, data = stroke_2_pred)$auc
roc(stroke ~ pred_M2_new, data = stroke_2_pred)$auc
```
